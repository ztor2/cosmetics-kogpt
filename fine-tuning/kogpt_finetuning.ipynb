{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYyD3MGlnL0m"
      },
      "source": [
        "참고링크\n",
        "- https://towardsdatascience.com/fine-tune-a-non-english-gpt-2-model-with-huggingface-9acc2dc7635b\n",
        "- https://colab.research.google.com/github/philschmid/fine-tune-GPT-2/blob/master/Fine_tune_a_non_English_GPT_2_Model_with_Huggingface.ipynb#scrollTo=hKBSyNLgqF9K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCclR_DIkP-0",
        "outputId": "c113dbae-bd56-4fef-d78d-fa0ce91f3852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDUB-HCDkQ9f",
        "outputId": "74c4fa4d-6bc7-4a6a-f170-8cabdce9bec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXh3dsD6n_ZH"
      },
      "outputs": [],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rSNNScCUwijO"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments,AutoModelWithLMHead\n",
        "from transformers import pipeline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import json\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings; warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_SSjhdlLY8Zn"
      },
      "outputs": [],
      "source": [
        "with open('cosmetic_comment_list_all.json', 'r', encoding='utf-8') as f:\n",
        "    data1 = json.load(f, strict=False)\n",
        "with open('final_other_platform0.15.json', 'r', encoding='utf-8') as f:\n",
        "    data2 = json.load(f, strict=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt1 = [data1[i]['review_text'] for i in range(len(data1))]\n",
        "# txt2 = [data2[i]['cmt_body'] for i in range(len(data2))]\n",
        "txt2 = [data2[i] for i in range(len(data2))]"
      ],
      "metadata": {
        "id": "hVWjZ_uNvDK1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = txt1 + txt2\n",
        "random.shuffle(txt)"
      ],
      "metadata": {
        "id": "sukyI2Jnwcle"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5s_boh04ENE",
        "outputId": "6427c9b7-d0c6-4791-d7f4-8995df50f646"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "237554"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZXHRJM9HnYya"
      },
      "outputs": [],
      "source": [
        "test_size = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lbYEGDesavLf"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(txt, test_size=test_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train), len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCX0fiKo1ubi",
        "outputId": "99f42cfc-0607-4ba6-894c-498408cb1113"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225676 11878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1gdKlex-a1sA"
      },
      "outputs": [],
      "source": [
        "train_concat = ' '.join(train)\n",
        "test_concat = ' '.join(test)\n",
        "train_concat = train_concat.replace('\\n', '  ')\n",
        "test_concat = test_concat.replace('\\n', '  ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oncG2AHTbNe_"
      },
      "outputs": [],
      "source": [
        "with open('train_dataset_v3.txt', 'w') as f:\n",
        "    f.write(train_concat)\n",
        "with open('test_dataset_v3.txt', 'w') as f:\n",
        "    f.write(test_concat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cRrmHmWnZOsT"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"models/tokenizer\")\n",
        "# tokenizer.save_pretrained(\"./models/tokenizer/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0vfchffOZOIk"
      },
      "outputs": [],
      "source": [
        "train_path = 'train_dataset_v3.txt'\n",
        "test_path = 'test_dataset_v3.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ku1cMDOWbkpl"
      },
      "outputs": [],
      "source": [
        "def load_dataset(train_path,test_path,tokenizer):\n",
        "    train_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=train_path,\n",
        "          block_size=128)\n",
        "     \n",
        "    test_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=test_path,\n",
        "          block_size=128)\n",
        "    \n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=False,\n",
        "    )\n",
        "    return train_dataset, test_dataset, data_collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qP9G2GGGbkiY"
      },
      "outputs": [],
      "source": [
        "train_dataset, test_dataset,data_collator = load_dataset(train_path, test_path, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8zQi5OXIbwVN"
      },
      "outputs": [],
      "source": [
        "model = AutoModelWithLMHead.from_pretrained(\"skt/kogpt2-base-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lnSEtmYmbwPs"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./cosmetics_kogpt_v2\", #The output directory\n",
        "\n",
        "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
        "    \n",
        "    num_train_epochs=5, # number of training epochs\n",
        "    per_device_train_batch_size=64, # batch size for training\n",
        "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
        "    eval_steps = 400, # Number of update steps between two evaluations.\n",
        "    save_steps= 800, # after # steps model is saved \n",
        "    warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
        "    prediction_loss_only=True,\n",
        "    # no_cuda=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kbqwrgM-bwJk"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Custom loss function 설정하기\n",
        "- 참고: https://huggingface.co/docs/transformers/main_classes/trainer"
      ],
      "metadata": {
        "id": "f6saig21GBVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class Trainer_with_custom_loss(Trainer):\n",
        "#     def compute_loss(self, model, inputs, return_outputs=False):\n",
        "#         labels = inputs.get(\"labels\")\n",
        "#         outputs = model(**inputs)\n",
        "#         logits = outputs.get('logits')\n",
        "#         loss_fct = nn.BCEWithLogitsLoss()\n",
        "#         loss = loss_fct(logits.view(-1, self.model.config.num_labels),\n",
        "#                         labels.float().view(-1, self.model.config.num_labels))\n",
        "#         return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "QPMBGaH9Fab4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer = Trainer_with_custom_loss(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     data_collator=data_collator,\n",
        "#     train_dataset=train_dataset,\n",
        "#     eval_dataset=test_dataset,\n",
        "# )"
      ],
      "metadata": {
        "id": "FzD56SgpFdRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "HrM6TljicEDo",
        "outputId": "b585d2c5-2c24-4a2f-89b3-95999187ccef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 116441\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 9100\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='149' max='9100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 149/9100 22:27 < 22:47:38, 0.11 it/s, Epoch 0.08/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUpbaAYfcDwe"
      },
      "outputs": [],
      "source": [
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bV90Qdk9H4D"
      },
      "source": [
        "### Generation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MkTcYZztrXA",
        "outputId": "3504edb9-a0ea-4a0d-9904-ff8d303a2abf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "generator = pipeline('text-generation', model='./gpt2_cosmetic_review_3ep', tokenizer=\"skt/kogpt2-base-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIW6Ux2MiYCi"
      },
      "outputs": [],
      "source": [
        "def review_generate(keyword, generator):\n",
        "    return print(generator(keyword)[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-16hudMj7hW",
        "outputId": "16fbde6a-0e9a-433b-e255-0f5d1119b657"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "블러셔로 써도 예뻐요!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
          ]
        }
      ],
      "source": [
        "review_generate('블러셔', generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAfUR5rK-ak4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "kogpt_finetuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}